{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import the neccessary module\n",
    "from helper import Model\n",
    "from helper import Auxiliary\n",
    "\n",
    "# Modelling\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.backend import clear_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preprocessing data\n",
      "Finished preprocessing data\n",
      "Start preprocessing data\n",
      "Finished preprocessing data\n"
     ]
    }
   ],
   "source": [
    "#df_train, df_test = Auxiliary.train_test_split(Auxiliary.preprocess_data(Model.get_csv('BPI_Challenge_2012.csv')))\n",
    "#read the data set\n",
    "df_train = Auxiliary.preprocess_data(Model.get_csv('BPI_Challenge_2012_train.csv'))\n",
    "df_test = Auxiliary.preprocess_data(Model.get_csv('BPI_Challenge_2012_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   org:resource  lifecycle:transition  concept:name  \\\n",
      "0         112.0                     2             0   \n",
      "1         112.0                     2             1   \n",
      "2         112.0                     2             2   \n",
      "3         112.0                     0             3   \n",
      "4           NaN                     1             3   \n",
      "\n",
      "                     time:timestamp                     case:REG_DATE  \\\n",
      "0  2011-09-30 22:38:44.546000+00:00  2011-09-30 22:38:44.546000+00:00   \n",
      "1  2011-09-30 22:38:44.880000+00:00  2011-09-30 22:38:44.546000+00:00   \n",
      "2  2011-09-30 22:39:37.906000+00:00  2011-09-30 22:38:44.546000+00:00   \n",
      "3  2011-09-30 22:39:38.875000+00:00  2011-09-30 22:38:44.546000+00:00   \n",
      "4  2011-10-01 09:36:46.437000+00:00  2011-09-30 22:38:44.546000+00:00   \n",
      "\n",
      "   case:concept:name  case:AMOUNT_REQ  A_SUBMITTED  A_PARTLYSUBMITTED  \\\n",
      "0             173688            20000            1                  0   \n",
      "1             173688            20000            0                  1   \n",
      "2             173688            20000            0                  0   \n",
      "3             173688            20000            0                  0   \n",
      "4             173688            20000            0                  0   \n",
      "\n",
      "   A_PREACCEPTED  ...  W_Nabellen incomplete dossiers  W_Beoordelen fraude  \\\n",
      "0              0  ...                               0                    0   \n",
      "1              0  ...                               0                    0   \n",
      "2              1  ...                               0                    0   \n",
      "3              0  ...                               0                    0   \n",
      "4              0  ...                               0                    0   \n",
      "\n",
      "   W_Wijzigen contractgegevens  year  month  day  hour  minute  second  \\\n",
      "0                            0  2011     09   30    22      38      44   \n",
      "1                            0  2011     09   30    22      38      44   \n",
      "2                            0  2011     09   30    22      39      37   \n",
      "3                            0  2011     09   30    22      39      38   \n",
      "4                            0  2011     10   01    09      36      46   \n",
      "\n",
      "   Next Event  \n",
      "0         1.0  \n",
      "1         2.0  \n",
      "2         3.0  \n",
      "3         3.0  \n",
      "4         4.0  \n",
      "\n",
      "[5 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train.columns())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# encode the concept:name as integer values\n",
    "df_encoded_train = df_train.copy()\n",
    "\n",
    "lengthOfDf = len(df_encoded_train.index)\n",
    "\n",
    "#add a new column with the position of each case\n",
    "df_encoded_train.at[0, 'position'] = 1\n",
    "j = 2\n",
    "for i in range(1, lengthOfDf):\n",
    "    if df_encoded_train.at[i, 'case:concept:name'] == df_encoded_train.at[i - 1, 'case:concept:name']:\n",
    "        df_encoded_train.at[i, 'position'] = j\n",
    "        j = j + 1\n",
    "    else :\n",
    "        df_encoded_train.at[i, 'position'] = 1\n",
    "        j = 2\n",
    "\n",
    "\n",
    "#the mode of the activities at a certain position\n",
    "df_mode = df_encoded_train.groupby('position')['concept:name'].agg(pd.Series.mode)\n",
    "\n",
    "#add a new column with the predicted time of each case and the ground truth\n",
    "for i in range(lengthOfDf - 1):\n",
    "    if df_encoded_train.at[i, 'position'] + 1 <= len(df_mode.index):\n",
    "        if (df_encoded_train.at[i + 1, 'position']) == 1:\n",
    "            df_encoded_train.at[i, 'Next time'] = 0\n",
    "        else:\n",
    "            df_encoded_train.at[i, 'Next time'] = Model.get_time_difference_as_number(df_encoded_train.at[i, 'time:timestamp'], df_encoded_train.at[i + 1, 'time:timestamp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# encode the concept:name as integer values\n",
    "df_encoded_test = df_test.copy()\n",
    "lengthOfDf = len(df_encoded_test.index)\n",
    "\n",
    "#add a new column with the position of each case\n",
    "df_encoded_test.at[0, 'position'] = 1\n",
    "j = 2\n",
    "for i in range(1, lengthOfDf):\n",
    "    if df_encoded_test.at[i, 'case:concept:name'] == df_encoded_test.at[i - 1, 'case:concept:name']:\n",
    "        df_encoded_test.at[i, 'position'] = j\n",
    "        j = j + 1\n",
    "    else :\n",
    "        df_encoded_test.at[i, 'position'] = 1\n",
    "        j = 2\n",
    "\n",
    "\n",
    "#the mode of the activities at a certain position\n",
    "df_mode = df_encoded_test.groupby('position')['concept:name'].agg(pd.Series.mode)\n",
    "\n",
    "#add a new column with the predicted time of each case and the ground truth\n",
    "for i in range(lengthOfDf - 1):\n",
    "    if df_encoded_test.at[i, 'position'] + 1 <= len(df_mode.index):\n",
    "        if (df_encoded_test.at[i + 1, 'position']) == 1:\n",
    "            df_encoded_test.at[i, 'Next time'] = 0\n",
    "        else:\n",
    "            df_encoded_test.at[i, 'Next time'] = Model.get_time_difference_as_number(df_encoded_test.at[i, 'time:timestamp'], df_encoded_test.at[i + 1, 'time:timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_to_drop = ['org:resource', 'lifecycle:transition', 'case:AMOUNT_REQ', 'Next Event', 'case:REG_DATE', 'concept:name', 'case:concept:name', 'time:timestamp', 'position', 'minute',\n",
    "       'second','year', 'month', 'hour']\n",
    "\n",
    "#split the data into training and test sets and drop some data\n",
    "x_train = df_encoded_train.drop(data_to_drop, axis=1)\n",
    "x_train = x_train.drop(['W_Wijzigen contractgegevens'], axis = 1)\n",
    "x_test = df_encoded_test.drop(data_to_drop, axis=1)\n",
    "x_train = x_train.drop(['Next time'], axis=1)\n",
    "x_test = x_test.drop(['Next time'], axis=1)\n",
    "\n",
    "y_train = df_encoded_train['Next time']\n",
    "y_test = df_encoded_test['Next time']\n",
    "\n",
    "#fill all empty values with nan\n",
    "x_train = x_train.replace(r'^\\s*$', np.nan, regex=True)\n",
    "x_test = x_test.replace(r'^\\s*$', np.nan, regex=True)\n",
    "y_train = y_train.replace(r'^\\s*$', np.nan, regex=True)\n",
    "y_test = y_test.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "\n",
    "#Fill all nan values with 0\n",
    "x_train = x_train.replace(np.nan,0)\n",
    "x_test = x_test.replace(np.nan,0)\n",
    "y_train = y_train.replace(np.nan,0)\n",
    "y_test = y_test.replace(np.nan,0)\n",
    "\n",
    "\n",
    "\n",
    "#TODO x_train,x_test \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test.head(10))\n",
    "print(y_test.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(x_test))\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import from_numpy\n",
    "#now everything is in array format\n",
    "train_x = x_train\n",
    "train_y = y_train\n",
    "test_x = x_test\n",
    "test_y = y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_x_list = []\n",
    "final_test_x_list = []\n",
    "for row in train_x.values:\n",
    "    entry_list = []\n",
    "    for value in row:\n",
    "        entry_list.append(value)\n",
    "    final_train_x_list.append(entry_list)\n",
    "entry_list = []\n",
    "for row in test_x.values:\n",
    "    entry_list = []\n",
    "    for value in row:\n",
    "        entry_list.append(value)\n",
    "    final_test_x_list.append(entry_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert entries to int\n",
    "for entry in final_train_x_list:\n",
    "    for i in range(len(entry)):\n",
    "        entry[i] = int(entry[i])\n",
    "for entry in final_test_x_list:\n",
    "    for i in range(len(entry)):\n",
    "        entry[i] = int(entry[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(final_train_x_list[0])\n",
    "print(final_test_x_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_y_list = []\n",
    "final_test_y_list = []\n",
    "for value in train_y.values:\n",
    "    final_train_y_list.append(value)\n",
    "for value in test_y.values:\n",
    "    final_test_y_list.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_y_list\n",
    "final_train_y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_dim = x_train.shape[1] # Number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = Sequential()\n",
    "  #model.add(Flatten(input_shape=(28, 28)))\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "  model.add(Dense(units=hp_units, activation='relu'))\n",
    "  model.add(Dense(10))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(optimizer=Adam(learning_rate=hp_learning_rate),\n",
    "                loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=100,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "x_test = tf.convert_to_tensor(x_test, dtype=tf.float32)\n",
    "y_test = tf.convert_to_tensor(y_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(final_train_x_list, final_train_y_list, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(4))\n",
    "\n",
    "\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "#model.compile(loss = 'binary_crossentropy', optimizer='rmsprop' metrics = ['accuracy'], )\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(final_train_x_list, final_train_y_list, epochs = 50, verbose = False, validation_data = (test_x, test_y), batch_size = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
